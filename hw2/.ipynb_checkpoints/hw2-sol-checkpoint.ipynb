{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# STA 141B Assignment 2\n",
    "\n",
    "Due __Feb 2, 2022__ by 11:59pm. \n",
    "\n",
    "Please rename this file with __\"LastName_FirstName_hw2\"__ \n",
    "\n",
    "The purpose of this assignment is to practice numpy, pandas, and use pandas data frames to index, slice, reshape, aggregate, and group data\n",
    "\n",
    "Notes: \n",
    "\n",
    "1. Please do not rename this file or delete the exercise cells. Put your answers in new cells after each exercise. You can make as many new cells as you like. Use code cells for code and Markdown cells for text. Answer all questions with complete sentences.\n",
    "\n",
    "2. Your code should be readable; writing a piece of code should be compared to writing a page of a book. Adopt the __one-statement-per-line__ rule. Consider splitting a lengthy statement into multiple lines to improve readability. (You will lose one point for each line that does not follow the one-statement-per-line rule)\n",
    "\n",
    "3. To help understand and maintain code, you should always add comments to explain your code. Use the _hash symbol_ (#) for writing a comment (homework without any comments will automatically receive 0 points). Use _docstring_ to explain a function\n",
    "\n",
    "4. Submit your final work with a __.pdf__ or a __.html__ file to Canvas. To convert a .ipynb file to a .pdf/.html file, go to \"File\", click \"Download as\", and then click \"PDF via LaTeX\"/\"HTML\". \n",
    "\n",
    "5. This assignment will be graded for correctness.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "exercise"
    ]
   },
   "source": [
    "### Part I: Indexing\n",
    "\n",
    "__Exercise 1.1 (10 points).__ Give three examples of indexing a data frame with `[ ]`, `.loc[ ]`, and `.iloc[ ]`, respectively. Explain how each of these indexing methods is different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#F00\">Grading</span>\n",
    "* each example: -1 incorrect / -2 missing\n",
    "* explanation: -2 incorrect / -4 missing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "first     a\n",
       "second    b\n",
       "third     c\n",
       "Name: y, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 3 POINTS\n",
    "x = pd.DataFrame({\"x\": [1, 2, 3], \"y\": [\"a\", \"b\", \"c\"]}, index = [\"first\", \"second\", \"third\"])\n",
    "\n",
    "# [ ] gets columns by name\n",
    "x[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x    1\n",
       "y    a\n",
       "Name: first, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 3 POINTS\n",
    "x.loc[\"first\", :] # .loc[ ] gets rows and columns by name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 3 POINTS\n",
    "x.iloc[0, 1] # .iloc[ ] gets rows and columns by position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "exercise"
    ]
   },
   "source": [
    "__Exercise 1.2 (10 points).__ What do negative indexes (as in `x[-1]`) do in Python? Create and try three examples of negative indexes for lists, NumPy arrays, and data frames, respectively. Then explain what you think negative indexes do. Confirm your explanation by linking to a relevant page in the Python, NumPy, or Pandas documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#F00\">Grading</span>\n",
    "* explanation: -2 incorrect / -4 missing\n",
    "* each example: -1 incorrect / -2 missing\n",
    "* link: -1 missing\n",
    "\n",
    "Link needs to be to official Python, NumPy, or Pandas docs -- not other websites."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negative indexes count from the end of the object. So `x[-1]` is the first element from the end, `x[-2]` is the second element from the end, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lists\n",
    "x = [1, 2, 3]\n",
    "x[-1] # first from end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NumPy arrays\n",
    "import numpy as np\n",
    "\n",
    "x = np.array([1, 2, 3, 4])\n",
    "x[-2] # second from end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   x  y\n",
      "0  1  4\n",
      "1  2  5\n",
      "2  3  6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "x    3\n",
       "y    6\n",
       "Name: 2, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pandas data frames\n",
    "x = pd.DataFrame({\"x\": [1, 2, 3], \"y\": [4, 5, 6]})\n",
    "print(x)\n",
    "\n",
    "x.iloc[-1, :] # first row from end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "exercise"
    ]
   },
   "source": [
    "__Exercise 1.3 (10 points).__ Give an example and explain Pandas' data alignment (or index alignment) feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#F00\">Grading</span>\n",
    "* explanation: -3 incorrect / -5 missing\n",
    "* example: -3 incorrect / -5 missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "a  2.0\n",
       "b  3.0\n",
       "c  NaN"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = pd.DataFrame([2, 3], index = [\"a\", \"b\"])\n",
    "y = pd.DataFrame([1, 1, 1], index = [\"b\", \"a\", \"c\"])\n",
    "y * x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas supports vectorized operations just like NumPy arrays. However, the elements in each Pandas series or data frame are matched for vectorized operations based on the row and column indexes (names) rather than by position.\n",
    "\n",
    "In the example above, rows \"a\" and \"b\" from each data frame are multiplied together. Since `x` doesn't have a row \"c\", Pandas returns `NaN` for that row's result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "exercise"
    ]
   },
   "source": [
    "__Exercise 1.4 (10 points).__ Explain the difference between the similarly-named data frame methods `.reindex()` and `.reset_index()`. Give two examples to show what each method respectively does.\n",
    "\n",
    "How might these methods be useful when combined with Pandas' data alignment feature?\n",
    "\n",
    "*Hint: Besides the Pandas documentation, `.reindex()` is explained in Python for Data Analysis 5.2, and `.reset_index()` is explained [here](https://jakevdp.github.io/PythonDataScienceHandbook/03.05-hierarchical-indexing.html#Index-setting-and-resetting).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#F00\">Grading</span>\n",
    "* each example: -1 incorrect / -3 missing\n",
    "* explanation: -2 incorrect / -4 missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Part 2: Read in the 'county_age_dist.csv' data and answer the next four questions.\n",
    "\n",
    "__Exercise 2.1 (5 points).__ Cast the 'fips' column as a string such that it is a length 5 string of digits that starts with 0 if it is currently of length 4.  Yolo county for example is '06113'.  This is the age distribution of each county in the US (with territories), you may notice that the total population is unusually large, please ignore this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#F00\">Grading</span>\n",
    "* read data: -1 incorrect / -2 missing\n",
    "* cast 'fips' as a string: -1 incorrect / -3 missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_age = pd.read_csv('county_age_dist.csv', dtype={'fips':str})\n",
    "county_age = county_age.set_index('fips')\n",
    "age_cols = list(county_age.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Exercise 2.2 (5 points).__ Create a population column which is the sum of the age counts for all age bins.  For each age bin create a column which is proportion of the age bin in the county populations, so for example '0-17_rat' is the ratio of '0-17' to the whole population for the county.  Print out the FIPS code for the county with the largest proportion of 0-17 year olds? What is the FIPS code for the county with the largest proportion of 85+ year olds?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#F00\">Grading</span>\n",
    "* each question: -0.5 incorrect/ -1 missing\n",
    "* if all missing: 0 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0-17_rat',\n",
       " '18-24_rat',\n",
       " '25-34_rat',\n",
       " '35-44_rat',\n",
       " '45-54_rat',\n",
       " '55-64_rat',\n",
       " '65-74_rat',\n",
       " '75-84_rat',\n",
       " '85+_rat']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "county_age['population'] = county_age.sum(axis=1)\n",
    "county_age = county_age.join(county_age[age_cols].div(county_age['population'],axis=0),rsuffix='_rat')\n",
    "age_rat_cols = [ac + '_rat' for ac in age_cols]\n",
    "age_rat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fips\n",
       "01001    0.242050\n",
       "01003    0.220623\n",
       "01005    0.213786\n",
       "01007    0.210674\n",
       "01009    0.227612\n",
       "           ...   \n",
       "72145    0.222862\n",
       "72147    0.217616\n",
       "72149    0.234818\n",
       "72151    0.211635\n",
       "72153    0.213282\n",
       "Name: 0-17_rat, Length: 3220, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "county_age[age_rat_cols[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'02158'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Largest proportion of 0-17 year olds\n",
    "county_age[age_rat_cols[0]].idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'31091'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Largest proportion of 85+ year olds\n",
    "county_age[age_rat_cols[-1]].idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Exercise 2.3 (5 points).__ What is the overall proportion of each age bin within the entire US.  You need to find the total number of each age bin across all counties and take the ratio with the total population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0-17     0.224884\n",
       "18-24    0.117452\n",
       "25-34    0.128200\n",
       "35-44    0.119159\n",
       "45-54    0.124014\n",
       "55-64    0.123719\n",
       "65-74    0.089391\n",
       "75-84    0.050112\n",
       "85+      0.023068\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Age proportions for all US\n",
    "\n",
    "county_age_sum = county_age.sum()\n",
    "county_age_sum[age_cols] / county_age_sum['population']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0-17          1.423394e+08\n",
       "18-24         7.434078e+07\n",
       "25-34         8.114383e+07\n",
       "35-44         7.542108e+07\n",
       "45-54         7.849398e+07\n",
       "55-64         7.830720e+07\n",
       "65-74         5.657975e+07\n",
       "75-84         3.171837e+07\n",
       "85+           1.460103e+07\n",
       "population    6.329454e+08\n",
       "0-17_rat      7.091123e+02\n",
       "18-24_rat     3.641499e+02\n",
       "25-34_rat     3.612024e+02\n",
       "35-44_rat     3.585490e+02\n",
       "45-54_rat     3.952437e+02\n",
       "55-64_rat     4.303425e+02\n",
       "65-74_rat     3.292618e+02\n",
       "75-84_rat     1.882375e+02\n",
       "85+_rat       8.390092e+01\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "county_age.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Exercise 2.4 (10 points).__ Create a new column that contains the mode of the age bins (the age bin with the largest proportion in the county).  Print out the frequencies of the modes different possible values, so that the frequency of '0-17' is the proportion of the counties that have '0-17' as the largest age bin for that county."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#F00\">Grading</span>\n",
    "* create a new column: -2 incorrect/ -5 missing\n",
    "* print out the frequencies: -2 incorrect/ -5 missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0-17_rat</th>\n",
       "      <th>18-24_rat</th>\n",
       "      <th>25-34_rat</th>\n",
       "      <th>35-44_rat</th>\n",
       "      <th>45-54_rat</th>\n",
       "      <th>55-64_rat</th>\n",
       "      <th>65-74_rat</th>\n",
       "      <th>75-84_rat</th>\n",
       "      <th>85+_rat</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fips</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01001</th>\n",
       "      <td>0.242050</td>\n",
       "      <td>0.106576</td>\n",
       "      <td>0.114909</td>\n",
       "      <td>0.129026</td>\n",
       "      <td>0.130631</td>\n",
       "      <td>0.118473</td>\n",
       "      <td>0.089520</td>\n",
       "      <td>0.050666</td>\n",
       "      <td>0.018148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01003</th>\n",
       "      <td>0.220623</td>\n",
       "      <td>0.095723</td>\n",
       "      <td>0.112451</td>\n",
       "      <td>0.119068</td>\n",
       "      <td>0.126571</td>\n",
       "      <td>0.133527</td>\n",
       "      <td>0.110206</td>\n",
       "      <td>0.059271</td>\n",
       "      <td>0.022560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01005</th>\n",
       "      <td>0.213786</td>\n",
       "      <td>0.119142</td>\n",
       "      <td>0.127668</td>\n",
       "      <td>0.114211</td>\n",
       "      <td>0.125483</td>\n",
       "      <td>0.123299</td>\n",
       "      <td>0.101605</td>\n",
       "      <td>0.054041</td>\n",
       "      <td>0.020766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01007</th>\n",
       "      <td>0.210674</td>\n",
       "      <td>0.114171</td>\n",
       "      <td>0.126086</td>\n",
       "      <td>0.119203</td>\n",
       "      <td>0.146106</td>\n",
       "      <td>0.121185</td>\n",
       "      <td>0.093018</td>\n",
       "      <td>0.055658</td>\n",
       "      <td>0.013898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01009</th>\n",
       "      <td>0.227612</td>\n",
       "      <td>0.100724</td>\n",
       "      <td>0.112028</td>\n",
       "      <td>0.120318</td>\n",
       "      <td>0.130666</td>\n",
       "      <td>0.125222</td>\n",
       "      <td>0.107338</td>\n",
       "      <td>0.058164</td>\n",
       "      <td>0.017928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72145</th>\n",
       "      <td>0.222862</td>\n",
       "      <td>0.119243</td>\n",
       "      <td>0.122765</td>\n",
       "      <td>0.116876</td>\n",
       "      <td>0.123953</td>\n",
       "      <td>0.119202</td>\n",
       "      <td>0.098397</td>\n",
       "      <td>0.050642</td>\n",
       "      <td>0.026059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72147</th>\n",
       "      <td>0.217616</td>\n",
       "      <td>0.125622</td>\n",
       "      <td>0.096370</td>\n",
       "      <td>0.108531</td>\n",
       "      <td>0.114981</td>\n",
       "      <td>0.136908</td>\n",
       "      <td>0.108900</td>\n",
       "      <td>0.069007</td>\n",
       "      <td>0.022066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72149</th>\n",
       "      <td>0.234818</td>\n",
       "      <td>0.133015</td>\n",
       "      <td>0.114193</td>\n",
       "      <td>0.110015</td>\n",
       "      <td>0.119715</td>\n",
       "      <td>0.128816</td>\n",
       "      <td>0.095785</td>\n",
       "      <td>0.045876</td>\n",
       "      <td>0.017767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72151</th>\n",
       "      <td>0.211635</td>\n",
       "      <td>0.118870</td>\n",
       "      <td>0.111495</td>\n",
       "      <td>0.121162</td>\n",
       "      <td>0.125759</td>\n",
       "      <td>0.129144</td>\n",
       "      <td>0.104395</td>\n",
       "      <td>0.049840</td>\n",
       "      <td>0.027699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72153</th>\n",
       "      <td>0.213282</td>\n",
       "      <td>0.110158</td>\n",
       "      <td>0.115657</td>\n",
       "      <td>0.116087</td>\n",
       "      <td>0.123096</td>\n",
       "      <td>0.131001</td>\n",
       "      <td>0.105211</td>\n",
       "      <td>0.056711</td>\n",
       "      <td>0.028798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3220 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0-17_rat  18-24_rat  25-34_rat  35-44_rat  45-54_rat  55-64_rat  \\\n",
       "fips                                                                     \n",
       "01001  0.242050   0.106576   0.114909   0.129026   0.130631   0.118473   \n",
       "01003  0.220623   0.095723   0.112451   0.119068   0.126571   0.133527   \n",
       "01005  0.213786   0.119142   0.127668   0.114211   0.125483   0.123299   \n",
       "01007  0.210674   0.114171   0.126086   0.119203   0.146106   0.121185   \n",
       "01009  0.227612   0.100724   0.112028   0.120318   0.130666   0.125222   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "72145  0.222862   0.119243   0.122765   0.116876   0.123953   0.119202   \n",
       "72147  0.217616   0.125622   0.096370   0.108531   0.114981   0.136908   \n",
       "72149  0.234818   0.133015   0.114193   0.110015   0.119715   0.128816   \n",
       "72151  0.211635   0.118870   0.111495   0.121162   0.125759   0.129144   \n",
       "72153  0.213282   0.110158   0.115657   0.116087   0.123096   0.131001   \n",
       "\n",
       "       65-74_rat  75-84_rat   85+_rat  \n",
       "fips                                   \n",
       "01001   0.089520   0.050666  0.018148  \n",
       "01003   0.110206   0.059271  0.022560  \n",
       "01005   0.101605   0.054041  0.020766  \n",
       "01007   0.093018   0.055658  0.013898  \n",
       "01009   0.107338   0.058164  0.017928  \n",
       "...          ...        ...       ...  \n",
       "72145   0.098397   0.050642  0.026059  \n",
       "72147   0.108900   0.069007  0.022066  \n",
       "72149   0.095785   0.045876  0.017767  \n",
       "72151   0.104395   0.049840  0.027699  \n",
       "72153   0.105211   0.056711  0.028798  \n",
       "\n",
       "[3220 rows x 9 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "county_age[age_rat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_age['mode'] = [age_cols[i] for i in np.argmax(county_age[age_rat_cols].values,axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fips\n",
       "01001    0-17\n",
       "01003    0-17\n",
       "01005    0-17\n",
       "01007    0-17\n",
       "01009    0-17\n",
       "         ... \n",
       "72145    0-17\n",
       "72147    0-17\n",
       "72149    0-17\n",
       "72151    0-17\n",
       "72153    0-17\n",
       "Name: mode, Length: 3220, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "county_age['mode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0-17     0.949379\n",
       "18-24    0.021739\n",
       "55-64    0.018012\n",
       "25-34    0.004658\n",
       "65-74    0.004658\n",
       "45-54    0.000932\n",
       "35-44    0.000621\n",
       "Name: mode, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Frequencies of mode\n",
    "\n",
    "county_age['mode'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3. Read in the 'county_fips_master.csv'' data and answer the next two questions\n",
    "\n",
    "__Exercise 3.1 (5 points).__ Join this dataset to the county age dataframe constructed above such that there is one row for every county in the new dataframe from county_fips_master. How many rows are there in the new dataframe? Are there any missing entries? If so how many rows have missingness?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#F00\">Grading</span>\n",
    "* Join the dataset: -1 incorrect/ -2 missing\n",
    "* other questions: -1 incorrect or missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xd0 in position 177435: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2548715/1056153053.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Read fips names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcounty_fips\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'county_fips_master.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'fips'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# reformat fips\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcounty_fips\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fips'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcounty_fips\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fips'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'str'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 932\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1233\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1234\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1235\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1236\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_dtype_objs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xd0 in position 177435: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "# Read fips names\n",
    "county_fips = pd.read_csv('county_fips_master.csv', dtype={'fips':str})\n",
    "\n",
    "# reformat fips\n",
    "county_fips['fips'] = county_fips['fips'].astype('str').str.zfill(5)\n",
    "county_fips = county_fips.set_index('fips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Left join (using index variable)\n",
    "county_data = county_fips.join(county_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of non-missings\n",
    "county_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_data[county_data.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the only missingness is in the above three counties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 3.2 (10 points)__ Drop any rows with missingness.  For each state calculate the proportion of each age bin as you did for the entire US in the question above.  What is the state with the most 0-17 proportion and the state with the most 85+ proportion?  Give the proportions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#F00\">Grading</span>\n",
    "* Drop rows: -3 incorrect/ -6 missing\n",
    "* Give the proportions: -2 incorrect/ -4 missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data = county_data[['state_abbr'] + age_cols].groupby('state_abbr').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data['total'] = state_data[age_cols].sum(axis=1)\n",
    "state_data = state_data.join(state_data[age_cols].div(state_data['total'],axis=0), rsuffix='_rat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:.3f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data.loc[state_data[age_rat_cols[0]].idxmax()]\n",
    "# Utah has most 0-17 prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data.loc[state_data[age_rat_cols[-1]].idxmax()]\n",
    "# Rhode Island has most 85+ prop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4. Read in the 'time_series_covid19_deaths_US.csv' data and answer the next five questions\n",
    "\n",
    "__Exercise 4.1 (5 points).__ This data is the Johns Hopkins official US Covid-19 death cumulative counts for each date and county.  Restructure the dataframe such that it is 'tidy' and there is a column for date, deaths, population, and fips.  (Hint: look at pandas melt function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#F00\">Grading</span>\n",
    "* -2 incorrect/-5 missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deaths = pd.read_csv('time_series_covid19_deaths_US.csv')\n",
    "deaths = deaths.dropna(subset=['FIPS'])\n",
    "deaths = deaths[]\n",
    "deaths['FIPS'] = deaths['FIPS'].astype(int).astype(str).str.zfill(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deaths.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_cols = list(deaths.columns[12:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# melted data in death_data\n",
    "death_data = deaths[['FIPS', 'Population'] + date_cols]\\\n",
    "    .melt(id_vars=['FIPS','Population'])\\\n",
    "    .rename(columns = {'variable':'date', 'value': 'death_count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "death_data['date'] = pd.DatetimeIndex(death_data['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "death_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Yolo county data looks correct\n",
    "death_data.query('FIPS==\"06113\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 4.2 (5 points).__ Which county (give county name and state) has the highest proportion of deaths by 2/25/21 to the Population?  Use the population in the covid deaths datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#F00\">Grading</span>\n",
    "* each question: -2 incorrect/ -5 missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "death_cumm = death_data.query('date==\"2/25/21\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "death_cumm.set_index('FIPS', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "death_cumm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "death_cumm = death_cumm.join(county_fips).dropna() #dropping counties not in US states/terr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "death_cumm['death_prop'] = death_cumm.eval('death_count / Population')\n",
    "county_max = death_cumm['death_prop'].idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "death_cumm.loc[county_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jerauld County, SD had the highest death proportion 16 / 2013 people\n",
    "death_cumm.loc[county_max]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 4.3 (10 points).__ Compute the incidence proportion (number of deaths each day per 100,000 population) for each county, you may save this as a new dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#F00\">Grading</span>\n",
    "* incorrect -3/ missing -10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexing and sort makes it much faster to do the next step!\n",
    "death_data = death_data.set_index(['FIPS','date']).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# series object that contains the incidence numbers \n",
    "death_inc = death_data.eval('death_count / Population * 1e5')\\\n",
    "    .groupby(level=0).diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "death_inc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Looks like there was a large correction in June for Yolo deaths\n",
    "death_inc['06113'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# esc + A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "death_inc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 4.4 (15 points).__ Compute the incidence proportion per week (per 100,000 population), which is the sum of the incidences for all days in a week.  Hint: use Periods in Pandas.  Which is the week with the highest mean incidence proportions (where the mean is taken over all the counties)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#F00\">Grading</span>\n",
    "* Compute the incidence proportion: -5 incorrect/ -10 missing\n",
    "* sum of the incidence: -2 incorrect/ -5 missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "death_inc = death_inc.reset_index(level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "death_inc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "death_inc['week'] = pd.PeriodIndex(death_inc['date'], freq='W')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "death_inc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "death_inc_weekly = death_inc.set_index('week',append=True).groupby(level=[0,1]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "death_inc_weekly = death_inc.set_index('week',append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "death_inc_weekly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "death_inc_weekly_groupby = death_inc.set_index('week',append=True).groupby(level=[0,1]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "death_inc.set_index('week',append=True).groupby(level = [0,1]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "death_inc_weekly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "death_inc_weekly.loc['06113'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "death_week_mean = death_inc_weekly.groupby(level=1).mean()\n",
    "death_week_mean.loc[death_week_mean.idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'death_week_mean' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2548715/4226003446.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdeath_week_mean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'death_week_mean' is not defined"
     ]
    }
   ],
   "source": [
    "death_week_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The week with the highest week mean proportion is the week of 2020-12-07 to 2020-12-13."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 4.5 (15 points).__ For each week (should be roughly 40 weeks), compute the spearman correlation between the proportion of seniors in the county and the incidence proportion for that county at that week (each county is considered to be a sample for computing the correlation).  Print all correlations below.  This should be a single number for each week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#F00\">Grading</span>\n",
    "* incorrect -5/ missing -15 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "senior_prop = county_data[age_rat_cols[-3:]].sum(axis=1)\n",
    "senior_prop.name = \"seniors\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "death_inc_weekly = death_inc_weekly.rename(columns={0:'death_inc'}).reset_index(level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "death_inc_sen = death_inc_weekly.join(senior_prop).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spear_corr(df, method='spearman'):\n",
    "    corrs = df.corr(method=method)\n",
    "    return corrs.iloc[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "death_sen_corr = death_inc_sen.groupby('week').apply(spear_corr).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here are the numbers\n",
    "death_sen_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is a plot for us to look at\n",
    "death_sen_corr.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interestingly the correlations look different if you use pearson!\n",
    "death_inc_sen.groupby('week')\\\n",
    "    .apply(lambda df: spear_corr(df, method='pearson'))\\\n",
    "    .dropna()\\\n",
    "    .plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
